{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Short-form PDF processing"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import io\n", "import base64\n", "import pandas as pd\n", "from PIL import Image\n", "from utils.logging import logger\n", "from utils.byte_genie import ByteGenie"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## init byte-genie"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### init byte-genie in async mode (tasks will run in the background)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["bg_async = ByteGenie(\n", "    secrets_file='secrets.json',\n", "    task_mode='async',\n", "    verbose=1,\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### init byte-genie in sync mode (tasks will run in the foreground)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["bg_sync = ByteGenie(\n", "    secrets_file='secrets.json',\n", "    task_mode='sync',\n", "    verbose=1,\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## select documents to process"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["doc_names = [\n", "    'userid_demo-genie_uploadfilename_renewal-of-hydrant-hosespdf',\n", "    'userid_demo-genie_uploadfilename_aircon-servicingpdf',\n", "    'userid_demo-genie_uploadfilename_repair-of-vehiclespdf',\n", "    'userid_demo-genie_uploadfilename_utility-billspdf',\n", "    'userid_demo-genie_uploadfilename_purchase-of-material-geocom-engineeringpdf'\n", "]\n", "\"\"\"\n", "See document_processing/upload_files.py (.ipynb) or data_management/upload_files.py (.ipynb) to see how to upload documents \n", "\"\"\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["## process documents"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### trigger text and table extraction from documents"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["responses = []\n", "for doc_num, doc_name in enumerate(doc_names):\n", "    logger.info(f\"triggering text translation pipeline for ({doc_num}/{len(doc_names)}): {doc_name}\")\n", "    ## trigger text translation pipeline in async (background) mode, as it is a long-running task\n", "    resp = bg_async.translate_text_pipeline(\n", "        doc_name=doc_name\n", "    )\n", "    responses = responses + [resp]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### wait for the output to be ready"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## View page images"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### list image files"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["img_files = []\n", "missing_doc_names = []\n", "for doc_num, doc_name in enumerate(doc_names):\n", "    logger.info(f\"processing document ({doc_num}/{len(doc_names)}): {doc_name}\")\n", "    ## list page image files\n", "    img_files_ = bg_sync.list_doc_files(\n", "        doc_name=doc_name,\n", "        file_pattern=f\"*.png\"\n", "    ).get_data()\n", "    if img_files_:\n", "        img_files = img_files + img_files_\n", "    else:\n", "        missing_doc_names = missing_doc_names + [doc_name]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### select an image file"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["img_file = img_files[1]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### read selected image"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["img_str = bg_sync.read_file(img_file).get_data()\n", "img = base64.b64decode(img_str)\n", "img = Image.open(io.BytesIO(img))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### show selected image"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["img.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Read output"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### list extracted original table files"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["table_files = []\n", "missing_doc_names = []\n", "for resp_num, resp in enumerate(responses):\n", "    logger.info(f\"processing response ({resp_num}/{len(responses)}\")\n", "    ## get doc_name\n", "    doc_name = resp.response['response']['task_1']['task']['args']['doc_name']\n", "    ## list original table files\n", "    table_files_ = bg_sync.list_doc_files(\n", "        doc_name=doc_name,\n", "        file_pattern=f\"variable_desc=orig-table/**.csv\"\n", "    ).get_data()\n", "    if table_files_:\n", "        table_files = table_files + table_files_\n", "    else:\n", "        missing_doc_names = missing_doc_names + [doc_name]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### documents with missing table files"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["logger.info(f\"documents with missing table files: {missing_doc_names}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### read table files"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tables_dict = {}\n", "for file_num, file in enumerate(table_files):\n", "    logger.info(f\"reading table file ({file_num}/{len(table_files)}): {file}\")\n", "    filename = file.split('/')[-1]\n", "    table = bg_sync.read_file(file).get_data()\n", "    tables_dict[filename] = table"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### check tables"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["logger.info(f\"filenames for tables: {list(tables_dict.keys())}\")\n", "\"\"\"\n", "list(tables_dict.keys())\n", "['renewal-of-hydrant-hosespdf_pagenum-0_table-cells_trans_orig-table_tablenum-0.csv', 'renewal-of-hydrant-hosespdf_pagenum-0_table-cells_trans_orig-table_tablenum-1.csv', 'renewal-of-hydrant-hosespdf_pagenum-0_table-cells_trans_orig-table_tablenum-2.csv', 'renewal-of-hydrant-hosespdf_pagenum-0_table-cells_trans_orig-table_tablenum-3.csv', 'renewal-of-hydrant-hosespdf_pagenum-1_table-cells_trans_orig-table_tablenum-0.csv', 'renewal-of-hydrant-hosespdf_pagenum-1_table-cells_trans_orig-table_tablenum-1.csv', 'renewal-of-hydrant-hosespdf_pagenum-1_table-cells_trans_orig-table_tablenum-2.csv', 'renewal-of-hydrant-hosespdf_pagenum-2_table-cells_trans_orig-table_tablenum-0.csv', 'renewal-of-hydrant-hosespdf_pagenum-3_table-cells_trans_orig-table_tablenum-0.csv', 'renewal-of-hydrant-hosespdf_pagenum-3_table-cells_trans_orig-table_tablenum-1.csv', 'renewal-of-hydrant-hosespdf_pagenum-4_table-cells_trans_orig-table_tablenum-0.csv', 'repair-of-vehiclespdf_pagenum-0_table-cells_trans_orig-table_tablenum-0.csv', 'repair-of-vehiclespdf_pagenum-0_table-cells_trans_orig-table_tablenum-1.csv', 'repair-of-vehiclespdf_pagenum-0_table-cells_trans_orig-table_tablenum-2.csv', 'repair-of-vehiclespdf_pagenum-0_table-cells_trans_orig-table_tablenum-3.csv', 'repair-of-vehiclespdf_pagenum-1_table-cells_trans_orig-table_tablenum-0.csv', 'repair-of-vehiclespdf_pagenum-1_table-cells_trans_orig-table_tablenum-1.csv', 'repair-of-vehiclespdf_pagenum-1_table-cells_trans_orig-table_tablenum-2.csv', 'repair-of-vehiclespdf_pagenum-1_table-cells_trans_orig-table_tablenum-3.csv', 'repair-of-vehiclespdf_pagenum-1_table-cells_trans_orig-table_tablenum-4.csv', 'repair-of-vehiclespdf_pagenum-2_table-cells_trans_orig-table_tablenum-0.csv', 'repair-of-vehiclespdf_pagenum-3_table-cells_trans_orig-table_tablenum-0.csv', 'repair-of-vehiclespdf_pagenum-3_table-cells_trans_orig-table_tablenum-1.csv', 'repair-of-vehiclespdf_pagenum-3_table-cells_trans_orig-table_tablenum-2.csv', 'repair-of-vehiclespdf_pagenum-3_table-cells_trans_orig-table_tablenum-3.csv', 'repair-of-vehiclespdf_pagenum-3_table-cells_trans_orig-table_tablenum-4.csv', 'repair-of-vehiclespdf_pagenum-4_table-cells_trans_orig-table_tablenum-0.csv', 'repair-of-vehiclespdf_pagenum-4_table-cells_trans_orig-table_tablenum-1.csv', 'utility-billspdf_pagenum-0_table-cells_trans_orig-table_tablenum-0.csv', 'utility-billspdf_pagenum-0_table-cells_trans_orig-table_tablenum-1.csv', 'utility-billspdf_pagenum-0_table-cells_trans_orig-table_tablenum-2.csv', 'utility-billspdf_pagenum-1_table-cells_trans_orig-table_tablenum-0.csv', 'utility-billspdf_pagenum-1_table-cells_trans_orig-table_tablenum-1.csv', 'utility-billspdf_pagenum-1_table-cells_trans_orig-table_tablenum-2.csv', 'utility-billspdf_pagenum-1_table-cells_trans_orig-table_tablenum-3.csv', 'utility-billspdf_pagenum-2_table-cells_trans_orig-table_tablenum-0.csv', 'purchase-of-material-geocom-engineeringpdf_pagenum-0_table-cells_trans_orig-table_tablenum-0.csv', 'purchase-of-material-geocom-engineeringpdf_pagenum-0_table-cells_trans_orig-table_tablenum-1.csv', 'purchase-of-material-geocom-engineeringpdf_pagenum-0_table-cells_trans_orig-table_tablenum-2.csv', 'purchase-of-material-geocom-engineeringpdf_pagenum-1_table-cells_trans_orig-table_tablenum-0.csv', 'purchase-of-material-geocom-engineeringpdf_pagenum-1_table-cells_trans_orig-table_tablenum-1.csv']\n", "Notice that all extracted pages are indexed by page number and table number within the page.\n", "tables_dict[list(tables_dict.keys())[0]]\n", "[{'nan': 'Date :', 'nan_2': '09/12/2015'}, {'nan': 'Cheque No :', 'nan_2': '4509'}, {'nan': 'Bank Code :', 'nan_2': '7302'}, {'nan': 'Account No :', 'nan_2': '04060352312'}, {'nan': 'Voucher No :', 'nan_2': '2015/16966'}]\n", "tables_dict[list(tables_dict.keys())[1]]\n", "[{'A/C Category': '', 'Acct Code': '', 'Amount': 115.81, 'Description': 'Being payment of below invoice for renew of hyd hose'}, {'A/C Category': 'Total Amount :', 'Acct Code': 'Total Amount :', 'Amount': 115.81, 'Description': 'Total Amount :'}, {'A/C Category': '', 'Acct Code': 'Total Tax :', 'Amount': 8.11, 'Description': ''}, {'A/C Category': '', 'Acct Code': 'Grand Total :', 'Amount': 123.92, 'Description': ''}]\n", "tables_dict[list(tables_dict.keys())[17]]\n", "[{'Amount (SGD)': 405.0, 'Description': 'SD5 12V COMPRESSOR 6321', 'GST': '7% SR', 'Quantity': 1.0, 'Rate': 405.0}, {'Amount (SGD)': '', 'Description': 'RECEIVER DRIER', 'GST': '7% SR', 'Quantity': 1.0, 'Rate': ''}, {'Amount (SGD)': '', 'Description': 'TOP UP COMPRESSOR OIL', 'GST': '7% SR', 'Quantity': 1.0, 'Rate': ''}, {'Amount (SGD)': '', 'Description': 'CHARGING GAS', 'GST': '7% SR', 'Quantity': 1.0, 'Rate': ''}, {'Amount (SGD)': '', 'Description': 'LABOUR CHARGES', 'GST': '7% SR', 'Quantity': 1.0, 'Rate': ''}, {'Amount (SGD)': '', 'Description': '', 'GST': '', 'Quantity': '', 'Rate': ''}]\n", "tables_dict[list(tables_dict.keys())[31]]\n", "[{'Amount ($)': '1,324.58', 'SUMMARY OF CHARGES 21 Oct 2015 to 19 Nov 2015': 'Balance B/F from Previous Bill'}, {'Amount ($)': '-1,324.58', 'SUMMARY OF CHARGES 21 Oct 2015 to 19 Nov 2015': 'Payment on 06-11-2015- Thank You'}, {'Amount ($)': '0.00', 'SUMMARY OF CHARGES 21 Oct 2015 to 19 Nov 2015': 'Outstanding Balance'}, {'Amount ($)': '8,399.53', 'SUMMARY OF CHARGES 21 Oct 2015 to 19 Nov 2015': 'Total Current Charges due on 15 Dec 2015 (Tue)'}, {'Amount ($)': '$8,399.53', 'SUMMARY OF CHARGES 21 Oct 2015 to 19 Nov 2015': 'Total Amount Payable'}]\n", "\"\"\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Re-structure data into desired form"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### init empty dict to store restructured datasets"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["datasets_dict = {}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### restructure table 0"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["table_key = list(tables_dict.keys())[0]\n", "resp = bg_async.create_dataset(\n", "    data=tables_dict[table_key],\n", "    attrs=['date', 'bank_number', 'cheque_number', 'account_number', 'voucher_number']\n", ")\n", "if resp.check_output_file_exists():\n", "    datasets_dict[table_key] = pd.DataFrame(resp.read_output_data())\n", "    ## pivot data\n", "    datasets_dict[table_key] = \\\n", "        pd.pivot(\n", "            data=datasets_dict[table_key],\n", "            index=['context', 'row_num'],\n", "            columns='variable',\n", "            values='value'\n", "        ).reset_index()\n", "    ## check datasets_dict[table_key]\n", "    \"\"\"\n", "    list(datasets_dict[table_key].columns)\n", "    ['context', 'row_num', 'account_number', 'bank_number', 'cheque_number', 'date', 'relevant quote', 'voucher_number']\n", "    'context' column contains the the original context from which the data is extracted\n", "    'relevant quote' column contains any specific relevant quote in the context relevant to extracted data\n", "    datasets_dict[table_key].drop(columns=['context', 'relevant quote', 'row_num']).to_dict('records')\n", "    [{'account_number': '04060352312', 'bank_number': '7302', 'cheque_number': '4509', 'date': '09/12/2015', 'voucher_number': '2015/16966'}]\n", "    \"\"\"\n", "else:\n", "    logger.warning(f\"output file {resp.get_output_file()} does not yet exist: try again later\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### restructure table 17"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["table_key = list(tables_dict.keys())[17]\n", "resp = bg_async.create_dataset(\n", "    data=tables_dict[table_key],\n", "    attrs=['product_purchased', 'payment_amount', 'payment_currency', 'sales_tax', 'transaction_description', 'any_additional_details']\n", ")\n", "if resp.check_output_file_exists():\n", "    datasets_dict[table_key] = pd.DataFrame(resp.read_output_data())\n", "    ## pivot data\n", "    datasets_dict[table_key] = \\\n", "        pd.pivot(\n", "            data=datasets_dict[table_key],\n", "            index=['context', 'row_num'],\n", "            columns='variable',\n", "            values='value'\n", "        ).reset_index()\n", "    ## check datasets_dict[table_key]\n", "    \"\"\"\n", "    list(datasets_dict[table_key].columns)\n", "    ['context', 'row_num', 'any_additional_details', 'payment_amount', 'payment_currency', 'product_purchased', 'relevant quote', 'sales_tax', 'transaction_description']\n", "    'context' column contains the the original context from which the data is extracted\n", "    'relevant quote' column contains any specific relevant quote in the context relevant to extracted data\n", "    datasets_dict[table_key].drop(columns=['context', 'relevant quote', 'row_num']).to_dict('records')\n", "    [{'any_additional_details': '', 'payment_amount': 'SGD 405', 'payment_currency': 'SGD', 'product_purchased': 'SD5 12V COMPRESSOR 6321', 'sales_tax': '7% SR', 'transaction_description': ''}, {'any_additional_details': '', 'payment_amount': 'n/a', 'payment_currency': 'SGD', 'product_purchased': 'RECEIVER DRIER', 'sales_tax': '7% SR', 'transaction_description': ''}, {'any_additional_details': '', 'payment_amount': 'n/a', 'payment_currency': 'SGD', 'product_purchased': 'TOP UP COMPRESSOR OIL', 'sales_tax': '7% SR', 'transaction_description': ''}, {'any_additional_details': '', 'payment_amount': 'n/a', 'payment_currency': 'SGD', 'product_purchased': 'CHARGING GAS', 'sales_tax': '7% SR', 'transaction_description': ''}, {'any_additional_details': '', 'payment_amount': 'n/a', 'payment_currency': 'n/a', 'product_purchased': 'LABOUR CHARGES', 'sales_tax': 'n/a', 'transaction_description': ''}]\n", "    \"\"\"\n", "else:\n", "    logger.warning(f\"output file {resp.get_output_file()} does not yet exist: try again later\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Next steps"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "This example covers the short-form document processing, such as invoices, utility bills, etc.<br>\n", "For long-form document processing examples, see company_research/document_processing.py (.ipynb) file<br>\n", ""]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}